{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DUFYFYV26ldo",
        "outputId": "20ee205e-92c2-4bc3-9b39-09e6c18a02a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3dd2d9f6-e3ce-4d3a-9c4b-1dc5a689319a\", \"predicted_stock_prices_with_weekly_data.csv\", 799)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# Define the tickers for the companies\n",
        "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"NVDA\", \"NFLX\"]\n",
        "\n",
        "# Create a DataFrame to store all predictions\n",
        "predictions = pd.DataFrame()\n",
        "weekly_prices = pd.DataFrame()\n",
        "\n",
        "# Loop through each ticker symbol\n",
        "for ticker in tickers:\n",
        "    # Download historical stock data for the past 1 year\n",
        "    data = yf.download(tickers=ticker, period=\"1y\")[\"Adj Close\"]\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    training_data_size = int(len(data) * 0.8)\n",
        "    training_data = data[:training_data_size]\n",
        "    testing_data = data[training_data_size:]\n",
        "\n",
        "    # Scale the data using MinMaxScaler\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_training_data = scaler.fit_transform(training_data.values.reshape(-1, 1))\n",
        "\n",
        "    # Create sequences for LSTM model\n",
        "    look_back = 30\n",
        "    x_train, y_train = [], []\n",
        "    for i in range(look_back, len(scaled_training_data)):\n",
        "        x_train.append(scaled_training_data[i-look_back:i, 0])\n",
        "        y_train.append(scaled_training_data[i, 0])\n",
        "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "\n",
        "    # Build the LSTM model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "    model.add(LSTM(units=50))\n",
        "    model.add(Dense(units=1))\n",
        "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "    # Prepare the testing data for prediction\n",
        "    scaled_testing_data = scaler.transform(testing_data.values.reshape(-1, 1))\n",
        "    x_test = []\n",
        "    for i in range(look_back, len(scaled_testing_data)):\n",
        "        x_test.append(scaled_testing_data[i-look_back:i, 0])\n",
        "    x_test = np.array(x_test)\n",
        "\n",
        "    # Predict the closing price for the next day\n",
        "    predicted_closing_price = scaler.inverse_transform(model.predict(x_test[-1:].reshape(1, look_back, 1)))[0][0]\n",
        "\n",
        "    # Append the prediction to the predictions DataFrame\n",
        "    predictions.loc[ticker, 'Predicted Closing Price'] = predicted_closing_price\n",
        "\n",
        "    # Extract the last week's data and append to the weekly_prices DataFrame\n",
        "    week_data = data[-7:]\n",
        "    weekly_prices[ticker] = week_data.values\n",
        "\n",
        "    # Plot the stock price history\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(data.index, data.values, label=ticker)\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Adjusted Closing Price\")\n",
        "    plt.title(f\"Stock Price History for {ticker}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{ticker}_stock_price_history.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Concatenate the weekly prices with the predictions\n",
        "predictions = pd.concat([predictions, weekly_prices], axis=1)\n",
        "\n",
        "# Save the predictions with weekly data to a CSV file\n",
        "\n",
        "predictions.to_csv('predicted_stock_prices_with_weekly_data.csv')\n",
        "\n",
        "# Download the CSV file\n",
        "files.download('predicted_stock_prices_with_weekly_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "\n",
        "stock_symbol = \"GOOG\"  # Adjust to your desired stock\n",
        "data = yf.download(stock_symbol, period=\"5mo\", interval=\"1d\")\n",
        "\n",
        "# Define the lookback window for input data (example: 10 timesteps)\n",
        "# lookback_window = 10\n",
        "\n",
        "lookback_window = 100\n",
        "\n",
        "\n",
        "\n",
        "# Select the most recent 'lookback_window' closing prices\n",
        "x_input = data[\"Close\"][-lookback_window:].values.reshape((1, lookback_window, 1))\n",
        "\n",
        "# List to store predictions\n",
        "predictions = []\n",
        "\n",
        "# Loop to generate 5 predictions\n",
        "for _ in range(103):\n",
        "    # Predict the next value\n",
        "    prediction = model.predict(x_input)\n",
        "    # Store the predicted value\n",
        "    predictions.append(prediction[0][0])\n",
        "    # Update the sequence by removing the first element and appending the new prediction\n",
        "    x_input = np.append(x_input[0][1:], prediction).reshape((1, lookback_window, 1))\n",
        "\n",
        "# If data was scaled, reverse scaling for predicted values\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(data[\"Close\"].values.reshape(-1, 1))\n",
        "predicted_prices = scaler.inverse_transform(np.array(predictions).reshape(-1, 1)).flatten()\n",
        "\n",
        "print(\"Predicted closing prices for the last 5 months:\", predicted_prices)\n",
        "\n",
        "\n",
        "\n",
        "test_data = data[-103:]\n",
        "\n",
        "\n",
        "pd_test = pd.DataFrame(test_data)\n",
        "# print (pd_test)\n",
        "\n",
        "last_close = pd_test[\"Close\"]\n",
        "\n",
        "\n",
        "\n",
        "mae = np.mean(np.abs(predicted_prices - last_close))\n",
        "\n",
        "# Calculate the mean of the actual values\n",
        "mean_actual = np.mean(last_close)\n",
        "\n",
        "# Calculate relative error\n",
        "relative_error = mae / mean_actual\n",
        "\n",
        "# Calculate accuracy as a percentage\n",
        "accuracy_percentage = (1 - relative_error) * 100\n",
        "\n",
        "print(\"Accuracy Percentage:\", accuracy_percentage, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z487NijDC4Vk",
        "outputId": "ca939993-8615-465c-ed1e-f45bcb918e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 53ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted closing prices for the last 5 months: [200.23433 211.29164 214.65779 215.75845 215.49046 214.53726 213.32692\n",
            " 212.08125 210.89505 209.83974 208.9132  207.96237 206.73428 205.05414\n",
            " 202.92494 200.48566 197.92538 195.423   193.1096  191.02164 189.04352\n",
            " 186.92746 184.46497 181.65419 178.7147  176.01268 173.97263 172.98355\n",
            " 173.28662 174.8721  177.44853 180.50867 183.45906 185.76218 187.05511\n",
            " 187.21092 186.32431 184.64195 182.48288 180.18132 178.05481 176.38106\n",
            " 175.36975 175.12862 175.6374  176.74643 178.20625 179.72023 181.00507\n",
            " 181.84459 182.12451 181.84077 181.0839  180.0089  178.8026  177.6544\n",
            " 176.73177 176.15854 175.99794 176.24297 176.81882 177.59859 178.42865\n",
            " 179.15854 179.6682  179.88669 179.79959 179.44472 178.89963 178.26479\n",
            " 177.64622 177.13942 176.81575 176.71281 176.82988 177.12987 177.54738\n",
            " 178.00182 178.41246 178.7127  178.86037 178.84256 178.67503 178.39656\n",
            " 178.06053 177.72516 177.44409 177.25829 177.1904  177.24231 177.39592\n",
            " 177.61757 177.8647  178.09377 178.26768 178.36168 178.36638 178.2879\n",
            " 178.14557 177.96745 177.78522 177.62874 177.52141]\n",
            "Accuracy Percentage: 72.60680648621954 %\n"
          ]
        }
      ]
    }
  ]
}
